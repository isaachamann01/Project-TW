{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get our data for csv.\n",
    "df = pd.read_csv('StockData/BTCUSDT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets all of our averages.\n",
    "\n",
    "def get_averages(data):\n",
    "\n",
    "    # only take close and open\n",
    "    data = data[['Close', 'Open']]\n",
    "\n",
    "    print(data)\n",
    "\n",
    "    data['MA5'] = data['Close'].rolling(window=5).mean()\n",
    "\n",
    "    data['MA20'] = data['Close'].rolling(window=20).mean()\n",
    "\n",
    "    data['MA60'] = data['Close'].rolling(window=60).mean()\n",
    "\n",
    "    # data['MA720'] = data['Close'].rolling(window=720).mean()\n",
    "\n",
    "    # data['MA1440'] = data['Close'].rolling(window=1440).mean()\n",
    "\n",
    "    data['MA10080'] = data['Close'].rolling(window=10080).mean()\n",
    "\n",
    "    # data['MA131400'] = data['Close'].rolling(window=131400).mean()\n",
    "\n",
    "    # Drop if even one of the values is na\n",
    "    data = data.dropna()\n",
    "\n",
    "    newdata = data[['Close', 'MA5', 'MA20', 'MA60', 'MA10080']].values\n",
    "\n",
    "    return newdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Close      Open\n",
      "0         4261.48   4261.48\n",
      "1         4261.48   4261.48\n",
      "2         4280.56   4280.56\n",
      "3         4261.48   4261.48\n",
      "4         4261.48   4261.48\n",
      "...           ...       ...\n",
      "3379522  39947.75  39945.00\n",
      "3379523  39957.68  39947.74\n",
      "3379524  39941.10  39957.69\n",
      "3379525  39961.09  39941.11\n",
      "3379526  39963.35  39961.09\n",
      "\n",
      "[3379527 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10216/1393116232.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['MA5'] = data['Close'].rolling(window=5).mean()\n",
      "/tmp/ipykernel_10216/1393116232.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['MA20'] = data['Close'].rolling(window=20).mean()\n",
      "/tmp/ipykernel_10216/1393116232.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['MA60'] = data['Close'].rolling(window=60).mean()\n",
      "/tmp/ipykernel_10216/1393116232.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['MA10080'] = data['Close'].rolling(window=10080).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3369448, 5)\n",
      "[[0.01959083 0.01946232 0.01921324 0.01862759 0.01269887]\n",
      " [0.01959083 0.01935492 0.01922354 0.01862294 0.01269863]\n",
      " [0.01959083 0.01935492 0.01921866 0.01861066 0.0126984 ]\n",
      " ...\n",
      " [0.56093105 0.56262899 0.56403235 0.56384613 0.60153578]\n",
      " [0.5612331  0.56267781 0.5640601  0.56384734 0.60153359]\n",
      " [0.56126724 0.56273348 0.56409752 0.56384538 0.6015315 ]]\n"
     ]
    }
   ],
   "source": [
    "def normalise_averages(averages):\n",
    "    \n",
    "    # Normalise each column of the 2d array\n",
    "    for i in range(averages.shape[1]):\n",
    "        averages[:, i] = (averages[:, i] - averages[:, i].min()) / (averages[:, i].max() - averages[:, i].min())\n",
    "\n",
    "    return averages\n",
    "\n",
    "avg = get_averages(df)\n",
    "\n",
    "print (avg.shape)\n",
    "\n",
    "avg = normalise_averages(avg)\n",
    "\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3369393, 50, 5) (3369393,)\n"
     ]
    }
   ],
   "source": [
    "def create_sequences(data, seq_length, future_steps):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data)-seq_length-future_steps):\n",
    "        x = data[i:i+seq_length]\n",
    "        # y is the mean over the next future_steps entries\n",
    "        y = np.mean(data[i+seq_length:i+seq_length+future_steps, 0])\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "seq_length = 50  # Example: 50 days of past data\n",
    "future_steps = 5  # Predicting the next 5 closing prices\n",
    "\n",
    "x, y = create_sequences(avg, seq_length, future_steps)\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models,losses\n",
    "\n",
    "train_size = int(len(x) * 0.8)\n",
    "x_train, x_test = x[:train_size], x[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Now we create a RNN model\n",
    "\n",
    "# Create model\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.LSTM(100, return_sequences=True, input_shape=(seq_length, x_train.shape[2])))\n",
    "model.add(layers.LSTM(100, return_sequences=False))\n",
    "model.add(layers.Dense(50))\n",
    "model.add(layers.Dense(1))  # Output layer with future_steps units\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss= losses.Huber(),\n",
    "              metrics= [losses.MeanAbsoluteError()],\n",
    ")\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=3, \n",
    "                    validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "84235/84235 [==============================] - 322s 4ms/step - loss: 6.1194e-07 - mean_absolute_error: 7.0115e-04 - val_loss: 1.0048e-06 - val_mean_absolute_error: 0.0014\n",
      "Epoch 2/10\n",
      "84235/84235 [==============================] - 327s 4ms/step - loss: 5.6240e-07 - mean_absolute_error: 6.7075e-04 - val_loss: 5.7895e-07 - val_mean_absolute_error: 9.9153e-04\n",
      "Epoch 3/10\n",
      "84235/84235 [==============================] - 323s 4ms/step - loss: 5.2451e-07 - mean_absolute_error: 6.4656e-04 - val_loss: 5.3648e-07 - val_mean_absolute_error: 9.6280e-04\n",
      "Epoch 4/10\n",
      "84235/84235 [==============================] - 327s 4ms/step - loss: 4.8190e-07 - mean_absolute_error: 6.1706e-04 - val_loss: 1.1095e-07 - val_mean_absolute_error: 3.0182e-04\n",
      "Epoch 5/10\n",
      "84235/84235 [==============================] - 324s 4ms/step - loss: 4.5676e-07 - mean_absolute_error: 5.9979e-04 - val_loss: 1.5956e-07 - val_mean_absolute_error: 3.8531e-04\n",
      "Epoch 6/10\n",
      "84235/84235 [==============================] - 331s 4ms/step - loss: 4.4327e-07 - mean_absolute_error: 5.9436e-04 - val_loss: 3.8220e-07 - val_mean_absolute_error: 7.8620e-04\n",
      "Epoch 7/10\n",
      "84235/84235 [==============================] - 327s 4ms/step - loss: 4.3062e-07 - mean_absolute_error: 5.8250e-04 - val_loss: 4.1437e-07 - val_mean_absolute_error: 7.7767e-04\n",
      "Epoch 8/10\n",
      "84235/84235 [==============================] - 328s 4ms/step - loss: 4.2087e-07 - mean_absolute_error: 5.7740e-04 - val_loss: 2.8035e-07 - val_mean_absolute_error: 5.5506e-04\n",
      "Epoch 9/10\n",
      "84235/84235 [==============================] - 328s 4ms/step - loss: 4.0916e-07 - mean_absolute_error: 5.6752e-04 - val_loss: 1.8811e-07 - val_mean_absolute_error: 5.0635e-04\n",
      "Epoch 10/10\n",
      "84235/84235 [==============================] - 328s 4ms/step - loss: 3.9791e-07 - mean_absolute_error: 5.5950e-04 - val_loss: 9.6101e-08 - val_mean_absolute_error: 2.7669e-04\n"
     ]
    }
   ],
   "source": [
    "# More epochs\n",
    "history = model.fit(x_train, y_train, epochs=10, \n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Extract loss values from the history object\u001b[39;00m\n\u001b[1;32m      4\u001b[0m loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract loss values from the history object\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Create a range for the number of epochs\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# Plot the loss values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, loss, 'bo-', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r*-', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nix/store/77j3ywj118fl439grgj9bcwrrvpjndpl-python3-3.11.8-env/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "model.save('BTCUSDT.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every minute for the date of 01-03-2024 we use the model to predict the mean next 5 closing prices.\n",
    "\n",
    "# First we need to get the data for that date\n",
    "df = pd.read_csv('StockData/BTCUSDT.csv')\n",
    "\n",
    "def get_averages(data):\n",
    "\n",
    "    # only take close and open\n",
    "    data = data[['Open time','Close', 'Open']]\n",
    "\n",
    "    data['MA5'] = data['Close'].rolling(window=5).mean()\n",
    "\n",
    "    data['MA20'] = data['Close'].rolling(window=20).mean()\n",
    "\n",
    "    data['MA60'] = data['Close'].rolling(window=60).mean()\n",
    "\n",
    "    data['MA10080'] = data['Close'].rolling(window=10080).mean()\n",
    "\n",
    "    # Drop if even one of the values is na\n",
    "    # data = data.dropna()\n",
    "\n",
    "    newdata = data[['Open time', 'Close', 'MA5', 'MA20', 'MA60', 'MA10080']]\n",
    "\n",
    "    return newdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10216/2879855496.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['MA5'] = data['Close'].rolling(window=5).mean()\n",
      "/tmp/ipykernel_10216/2879855496.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['MA20'] = data['Close'].rolling(window=20).mean()\n",
      "/tmp/ipykernel_10216/2879855496.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['MA60'] = data['Close'].rolling(window=60).mean()\n",
      "/tmp/ipykernel_10216/2879855496.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['MA10080'] = data['Close'].rolling(window=10080).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.60125108 0.60341201 0.60602269 0.60662421 0.64103057]\n",
      " [0.60230875 0.60348963 0.6059657  0.60656169 0.64102938]\n",
      " [0.60158107 0.60341865 0.60587351 0.60648785 0.64102812]\n",
      " [0.60149706 0.60335637 0.60577255 0.60641041 0.64102681]\n",
      " [0.60158893 0.60338766 0.60567892 0.6063368  0.64102549]\n",
      " [0.60138087 0.60341371 0.60559304 0.60625909 0.64102416]\n",
      " [0.60173791 0.60329915 0.60552887 0.60619268 0.64102288]\n",
      " [0.60207848 0.60339897 0.60548185 0.60613898 0.64102162]\n",
      " [0.60237629 0.60357541 0.60544003 0.60609539 0.64102048]\n",
      " [0.60244776 0.60374776 0.60539373 0.60604604 0.64101931]\n",
      " [0.60266141 0.60400474 0.60534101 0.60600467 0.64101822]\n",
      " [0.60287929 0.60423379 0.6053501  0.60597101 0.64101714]\n",
      " [0.60257679 0.60433379 0.6053652  0.6059517  0.64101605]\n",
      " [0.60246634 0.60435187 0.60539016 0.60592657 0.64101493]\n",
      " [0.60256607 0.60437561 0.60540854 0.60590532 0.64101385]\n",
      " [0.60347657 0.6045392  0.60547854 0.60588816 0.64101289]\n",
      " [0.60359186 0.60468219 0.60556259 0.60587713 0.64101191]\n",
      " [0.60379342 0.60492635 0.60565615 0.60588264 0.64101095]\n",
      " [0.60364595 0.60516307 0.6057487  0.60588265 0.64100995]\n",
      " [0.60362072 0.60537472 0.60585883 0.60590234 0.64100896]\n",
      " [0.60319009 0.60531723 0.60595643 0.60591705 0.64100783]\n",
      " [0.60337368 0.60527344 0.60601004 0.60591757 0.6410067 ]\n",
      " [0.60343668 0.60520185 0.60610344 0.60593099 0.6410056 ]\n",
      " [0.60271142 0.60501431 0.60616457 0.60592446 0.64100442]\n",
      " [0.60267909 0.60482534 0.60621945 0.60591584 0.64100333]\n",
      " [0.60268558 0.6047241  0.60628512 0.60591444 0.64100225]\n",
      " [0.60291963 0.60463298 0.60634461 0.60591698 0.64100123]\n",
      " [0.60278667 0.60450254 0.60638026 0.60591729 0.64100015]\n",
      " [0.60304187 0.60456885 0.60641376 0.60592188 0.64099909]\n",
      " [0.60334074 0.60470163 0.60645871 0.60594163 0.64099807]\n",
      " [0.60354018 0.60487313 0.60650295 0.60597008 0.64099705]\n",
      " [0.60348201 0.60498599 0.60653329 0.60599161 0.64099604]\n",
      " [0.60325235 0.60507944 0.60656729 0.60600508 0.64099498]\n",
      " [0.60292598 0.60505618 0.60659043 0.60602104 0.64099387]\n",
      " [0.60270764 0.60492914 0.60659756 0.6060344  0.64099274]\n",
      " [0.60311304 0.60484342 0.60657926 0.60605055 0.64099173]\n",
      " [0.60348367 0.60484375 0.60657381 0.60605873 0.64099079]\n",
      " [0.60361815 0.60491716 0.60656499 0.60606511 0.64098988]\n",
      " [0.60361634 0.6050557  0.6065635  0.60607551 0.64098895]\n",
      " [0.60419564 0.60535431 0.60659244 0.60609563 0.64098805]\n",
      " [0.60401644 0.6055356  0.60663403 0.6061107  0.64098708]\n",
      " [0.60360198 0.60555935 0.60664552 0.6061134  0.64098607]\n",
      " [0.6038256  0.60560098 0.6066651  0.60612034 0.64098511]\n",
      " [0.60406932 0.60569188 0.60673346 0.60612985 0.64098419]\n",
      " [0.60446081 0.6057451  0.60682314 0.60614684 0.64098329]\n",
      " [0.60446096 0.60583431 0.60691251 0.60616991 0.64098239]\n",
      " [0.60409395 0.60593303 0.60697162 0.60618807 0.64098142]\n",
      " [0.60436441 0.60604116 0.60705104 0.60621077 0.64098048]\n",
      " [0.60457353 0.60614235 0.60712814 0.60623371 0.64097952]\n",
      " [0.60481136 0.60621269 0.60720217 0.60625796 0.64097859]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def normalise_averages(averages):\n",
    "    \n",
    "    # For every column in the pd dataframe we normalise\n",
    "    for i in averages.columns[1:]:\n",
    "        averages[i] = (averages[i] - averages[i].min()) / (averages[i].max() - averages[i].min())\n",
    "\n",
    "    return averages\n",
    "\n",
    "testing = get_averages(df)\n",
    "\n",
    "testing = normalise_averages(testing)\n",
    "# only take the data from '2024-01-03'\n",
    "# get '2024-01-03 in unix time\n",
    "# assigned regular string date\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Normalise the values\n",
    "\n",
    "# testing = testing.dropna()\n",
    "# testing = \n",
    "\n",
    "\n",
    "testing['datetime'] = pd.to_datetime(testing['Open time'], unit='ms') \n",
    "\n",
    "# # take only the date of '2024-01-03'\n",
    "\n",
    "testing = testing[testing['datetime'].dt.date == datetime.strptime('2024-01-03', '%Y-%m-%d').date()]\n",
    "\n",
    "# # Now test these values with the model\n",
    "\n",
    "# # Get the last seq_length values\n",
    "\n",
    "last_values = testing[['Close', 'MA5', 'MA20', 'MA60', 'MA10080']].values[-seq_length:]\n",
    "\n",
    "# # Run the values through the model\n",
    "\n",
    "last_values = last_values.reshape(1, seq_length, 5)\n",
    "\n",
    "# # Predict the mean of the next 5 closing prices\n",
    "\n",
    "last_values = model.predict(last_values)\n",
    "\n",
    "print(last_values)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
